#!/usr/bin/env python3
"""
éªŒè¯ macOS OCR å†…å®¹æå–æ•ˆæœçš„å·¥å…·
Tool to verify macOS OCR content extraction effectiveness
"""

import sys
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def analyze_html_content(html_file_path: str) -> Dict:
    """åˆ†æ HTML æ–‡ä»¶å†…å®¹"""
    
    if not os.path.exists(html_file_path):
        return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {html_file_path}"}
    
    try:
        with open(html_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŸºæœ¬ç»Ÿè®¡
        stats = {
            "file_size": os.path.getsize(html_file_path),
            "total_characters": len(content),
            "total_lines": len(content.split('\n')),
        }
        
        # æå–é¡µé¢å†…å®¹
        pages = re.findall(r'<h2>Page (\d+)</h2>\s*<div class=\'page-content\'><p>(.*?)</p></div>', content, re.DOTALL)
        
        stats["total_pages"] = len(pages)
        stats["pages_with_content"] = 0
        stats["pages_content"] = []
        
        # åˆ†ææ¯é¡µå†…å®¹
        for page_num, page_content in pages:
            if page_content.strip():
                stats["pages_with_content"] += 1
                stats["pages_content"].append({
                    "page": int(page_num),
                    "character_count": len(page_content),
                    "word_count": len(page_content.split()),
                    "preview": page_content[:200] + ("..." if len(page_content) > 200 else "")
                })
        
        # æ£€æµ‹ä¸­æ–‡å†…å®¹
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', content)
        stats["chinese_characters"] = len(chinese_chars)
        stats["has_chinese"] = len(chinese_chars) > 0
        
        # æ£€æµ‹è‹±æ–‡å†…å®¹
        english_words = re.findall(r'\b[a-zA-Z]+\b', content)
        stats["english_words"] = len(english_words)
        stats["has_english"] = len(english_words) > 0
        
        # æ£€æµ‹ç‰¹å®šå…³é”®è¯ï¼ˆåŸºäºæ‚¨çš„æµ‹è¯•æ–‡æ¡£ï¼‰
        keywords = [
            "AIè¾…åŠ©è½¯ä»¶äº¤ä»˜æˆç†Ÿåº¦æ¨¡å‹",
            "L2çº§ Prompté©±åŠ¨å®è·µ",
            "Docling",
            "æˆç†Ÿåº¦",
            "äººå·¥æ™ºèƒ½",
            "è½¯ä»¶äº¤ä»˜",
            "RAG",
            "å‘é‡åŒ–"
        ]
        
        found_keywords = []
        for keyword in keywords:
            if keyword in content:
                found_keywords.append(keyword)
        
        stats["found_keywords"] = found_keywords
        stats["keyword_coverage"] = len(found_keywords) / len(keywords) if keywords else 0
        
        return stats
        
    except Exception as e:
        return {"error": f"è¯»å–æ–‡ä»¶å‡ºé”™: {str(e)}"}

def compare_extraction_methods(pdf_path: str) -> Dict:
    """æ¯”è¾ƒä¸åŒæå–æ–¹æ³•çš„æ•ˆæœ"""
    
    results = {}
    
    # æµ‹è¯• macOS OCR
    print("ğŸ æµ‹è¯• macOS OCR æå–...")
    try:
        from rag_poc.document_processing.macos_ocr_converter import MacOSOCRConverter
        
        converter = MacOSOCRConverter()
        output_file = converter.convert_file(pdf_path, "data/output/comparison_macos")
        
        if os.path.exists(output_file):
            results["macos_ocr"] = analyze_html_content(output_file)
            results["macos_ocr"]["output_file"] = output_file
        
    except Exception as e:
        results["macos_ocr"] = {"error": str(e)}
    
    # æµ‹è¯• SimplePDF
    print("ğŸ“„ æµ‹è¯• Simple PDF æå–...")
    try:
        from rag_poc.document_processing.simple_pdf_converter import SimplePDFConverter
        
        converter = SimplePDFConverter()
        output_file = converter.convert_file(pdf_path, "data/output/comparison_simple")
        
        if os.path.exists(output_file):
            results["simple_pdf"] = analyze_html_content(output_file)
            results["simple_pdf"]["output_file"] = output_file
        
    except Exception as e:
        results["simple_pdf"] = {"error": str(e)}
    
    return results

def extract_and_display_content(html_file_path: str, num_pages: int = 3):
    """æå–å¹¶æ˜¾ç¤º HTML æ–‡ä»¶çš„å…·ä½“å†…å®¹"""
    
    print(f"\nğŸ“– æ˜¾ç¤ºæ–‡ä»¶å†…å®¹: {Path(html_file_path).name}")
    print("=" * 80)
    
    try:
        with open(html_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–é¡µé¢å†…å®¹
        pages = re.findall(r'<h2>Page (\d+)</h2>\s*<div class=\'page-content\'><p>(.*?)</p></div>', content, re.DOTALL)
        
        for i, (page_num, page_content) in enumerate(pages[:num_pages]):
            print(f"\nğŸ“„ ç¬¬ {page_num} é¡µå†…å®¹:")
            print("-" * 50)
            
            # æ¸…ç† HTML å†…å®¹å¹¶æ˜¾ç¤º
            clean_content = page_content.strip()
            if clean_content:
                # æ˜¾ç¤ºå‰500å­—ç¬¦
                display_content = clean_content[:500]
                if len(clean_content) > 500:
                    display_content += "\n... [å†…å®¹å·²æˆªæ–­]"
                
                print(display_content)
            else:
                print("âš ï¸  æ­¤é¡µæ— æ–‡æœ¬å†…å®¹")
        
        if len(pages) > num_pages:
            print(f"\n... è¿˜æœ‰ {len(pages) - num_pages} é¡µå†…å®¹æœªæ˜¾ç¤º")
            
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å‡ºé”™: {e}")

def search_content_in_html(html_file_path: str, search_terms: List[str]):
    """åœ¨ HTML æ–‡ä»¶ä¸­æœç´¢ç‰¹å®šå†…å®¹"""
    
    print(f"\nğŸ” åœ¨ {Path(html_file_path).name} ä¸­æœç´¢å†…å®¹...")
    print("=" * 80)
    
    try:
        with open(html_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        for term in search_terms:
            print(f"\nğŸ¯ æœç´¢: '{term}'")
            
            # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…
            matches = []
            for match in re.finditer(re.escape(term), content, re.IGNORECASE):
                start = max(0, match.start() - 100)
                end = min(len(content), match.end() + 100)
                context = content[start:end]
                matches.append(context)
            
            if matches:
                print(f"âœ… æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…:")
                for i, context in enumerate(matches[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"  [{i}] ...{context}...")
                if len(matches) > 3:
                    print(f"  ... è¿˜æœ‰ {len(matches) - 3} ä¸ªåŒ¹é…")
            else:
                print("âŒ æœªæ‰¾åˆ°åŒ¹é…å†…å®¹")
                
    except Exception as e:
        print(f"âŒ æœç´¢å‡ºé”™: {e}")

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    
    print("ğŸ” macOS OCR å†…å®¹æå–éªŒè¯å·¥å…·")
    print("=" * 60)
    
    # é»˜è®¤æµ‹è¯•æ–‡ä»¶
    test_pdf = "data/input/AIè¾…åŠ©è½¯ä»¶äº¤ä»˜æˆç†Ÿåº¦æ¨¡å‹ç™½çš®ä¹¦.pdf"
    test_html = "data/output/test_macos/AIè¾…åŠ©è½¯ä»¶äº¤ä»˜æˆç†Ÿåº¦æ¨¡å‹ç™½çš®ä¹¦.html"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_pdf):
        print(f"âŒ æµ‹è¯• PDF æ–‡ä»¶ä¸å­˜åœ¨: {test_pdf}")
        return
    
    # 1. åˆ†æç°æœ‰çš„ HTML æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if os.path.exists(test_html):
        print("ğŸ“Š åˆ†æç°æœ‰çš„ macOS OCR æå–ç»“æœ...")
        stats = analyze_html_content(test_html)
        
        if "error" not in stats:
            print(f"\nğŸ“ˆ æå–ç»Ÿè®¡:")
            print(f"  æ–‡ä»¶å¤§å°: {stats['file_size']:,} å­—èŠ‚")
            print(f"  æ€»å­—ç¬¦æ•°: {stats['total_characters']:,}")
            print(f"  æ€»é¡µæ•°: {stats['total_pages']}")
            print(f"  æœ‰å†…å®¹é¡µæ•°: {stats['pages_with_content']}")
            print(f"  ä¸­æ–‡å­—ç¬¦æ•°: {stats['chinese_characters']:,}")
            print(f"  è‹±æ–‡å•è¯æ•°: {stats['english_words']:,}")
            print(f"  å…³é”®è¯è¦†ç›–: {stats['keyword_coverage']:.1%} ({len(stats['found_keywords'])}/{len(['AIè¾…åŠ©è½¯ä»¶äº¤ä»˜æˆç†Ÿåº¦æ¨¡å‹', 'L2çº§ Prompté©±åŠ¨å®è·µ', 'Docling', 'æˆç†Ÿåº¦', 'äººå·¥æ™ºèƒ½', 'è½¯ä»¶äº¤ä»˜', 'RAG', 'å‘é‡åŒ–'])})")
            
            if stats['found_keywords']:
                print(f"  æ‰¾åˆ°å…³é”®è¯: {', '.join(stats['found_keywords'])}")
        else:
            print(f"âŒ {stats['error']}")
        
        # æ˜¾ç¤ºå…·ä½“å†…å®¹
        extract_and_display_content(test_html, num_pages=2)
        
        # æœç´¢ç‰¹å®šå†…å®¹
        search_terms = [
            "L2çº§ Prompté©±åŠ¨å®è·µ",
            "AIè¾…åŠ©è½¯ä»¶äº¤ä»˜æˆç†Ÿåº¦æ¨¡å‹",
            "æˆç†Ÿåº¦æ¨¡å‹",
            "Docling",
            "å‘é‡åŒ–"
        ]
        search_content_in_html(test_html, search_terms)
    
    else:
        print(f"âš ï¸  macOS OCR ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {test_html}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python main.py --device macos build -f data/input/AIè¾…åŠ©è½¯ä»¶äº¤ä»˜æˆç†Ÿåº¦æ¨¡å‹ç™½çš®ä¹¦.pdf")
    
    # 2. æ¯”è¾ƒä¸åŒæå–æ–¹æ³•
    print(f"\n" + "=" * 60)
    print("ğŸ”„ æ¯”è¾ƒä¸åŒæå–æ–¹æ³•çš„æ•ˆæœ...")
    
    comparison = compare_extraction_methods(test_pdf)
    
    print(f"\nğŸ“Š æå–æ–¹æ³•å¯¹æ¯”:")
    print("-" * 60)
    
    for method, result in comparison.items():
        method_name = "macOS OCR" if method == "macos_ocr" else "Simple PDF"
        print(f"\n{method_name}:")
        
        if "error" in result:
            print(f"  âŒ é”™è¯¯: {result['error']}")
        else:
            print(f"  âœ… æ–‡ä»¶å¤§å°: {result['file_size']:,} å­—èŠ‚")
            print(f"  ğŸ“ æ€»å­—ç¬¦æ•°: {result['total_characters']:,}")
            print(f"  ğŸ“„ é¡µæ•°: {result['total_pages']}")
            print(f"  ğŸ‡¨ğŸ‡³ ä¸­æ–‡å­—ç¬¦: {result['chinese_characters']:,}")
            print(f"  ğŸ‡ºğŸ‡¸ è‹±æ–‡å•è¯: {result['english_words']:,}")
            print(f"  ğŸ¯ å…³é”®è¯è¦†ç›–: {result['keyword_coverage']:.1%}")
    
    # 3. ä½¿ç”¨å»ºè®®
    print(f"\n" + "=" * 60)
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®:")
    
    if "macos_ocr" in comparison and "error" not in comparison["macos_ocr"]:
        macos_stats = comparison["macos_ocr"]
        if macos_stats["chinese_characters"] > 0 and macos_stats["keyword_coverage"] > 0.5:
            print("âœ… macOS OCR æå–æ•ˆæœè‰¯å¥½ï¼Œæ¨èä½¿ç”¨")
            print("   å‘½ä»¤: python main.py --device macos build -f your_document.pdf")
        else:
            print("âš ï¸  macOS OCR æå–æ•ˆæœä¸€èˆ¬ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ–‡æ¡£è´¨é‡")
    
    print(f"\nğŸ“– æŸ¥çœ‹å®Œæ•´æå–å†…å®¹:")
    for method, result in comparison.items():
        if "output_file" in result:
            print(f"  {method}: {result['output_file']}")

if __name__ == "__main__":
    main()